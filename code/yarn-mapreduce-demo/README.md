# Yarn MapReduce Demo

è¿™æ˜¯ä¸€ä¸ªåŸºäºYARNçš„MapReduce WordCountç¤ºä¾‹é¡¹ç›®ï¼Œå±•ç¤ºäº†å¦‚ä½•å°†MapReduceä½œä¸šæäº¤åˆ°è¿œç¨‹YARNé›†ç¾¤ã€‚

## é¡¹ç›®ç‰¹æ€§

- **é…ç½®å¤–éƒ¨åŒ–**: æ‰€æœ‰Hadoopé…ç½®éƒ½å­˜å‚¨åœ¨ `hadoop.properties` æ–‡ä»¶ä¸­
- **é…ç½®ç®¡ç†å™¨**: ä½¿ç”¨ `HadoopConfigManager` ç»Ÿä¸€ç®¡ç†é…ç½®
- **ç¯å¢ƒæ„ŸçŸ¥**: æ”¯æŒå¼€å‘å’Œç”Ÿäº§ç¯å¢ƒçš„ä¸åŒé…ç½®
- **æ—¥å¿—ä¼˜åŒ–**: ç»“æ„åŒ–æ—¥å¿—è®°å½•å’Œé…ç½®ä¿¡æ¯æ‰“å°
- **è¿æ¥è¿œç¨‹HDFSé›†ç¾¤**: æ”¯æŒè¿æ¥åˆ°è¿œç¨‹Hadoopé›†ç¾¤
- **è‡ªåŠ¨å¤„ç†è¾“å‡ºç›®å½•å†²çª**: æ™ºèƒ½å¤„ç†å·²å­˜åœ¨çš„è¾“å‡ºç›®å½•

## é¡¹ç›®ç»“æ„

```
src/main/java/
â”œâ”€â”€ com/bigdata/config/
â”‚   â””â”€â”€ HadoopConfigManager.java    # é…ç½®ç®¡ç†å™¨
â””â”€â”€ com/bigdata/mapreduce/wordcount/
    â”œâ”€â”€ WordCountDriver.java         # ä¸»é©±åŠ¨ç¨‹åº
    â”œâ”€â”€ WordCountMapper.java         # Mapperå®ç°
    â””â”€â”€ WordCountReducer.java        # Reducerå®ç°

src/main/resources/
â””â”€â”€ hadoop.properties                # Hadoopé…ç½®æ–‡ä»¶
```

## é…ç½®æ–‡ä»¶è¯´æ˜

### hadoop.properties

è¯¥æ–‡ä»¶åŒ…å«æ‰€æœ‰Hadoopé›†ç¾¤çš„é…ç½®å‚æ•°ï¼Œæ”¯æŒä»¥ä¸‹é…ç½®ï¼š

```properties
# HDFSé…ç½®
fs.defaultFS=hdfs://10.132.144.24:9000

# YARN ResourceManageré…ç½®
yarn.resourcemanager.hostname=10.132.144.24
yarn.resourcemanager.address=10.132.144.24:8032

# JobHistoryServeré…ç½®
mapreduce.jobhistory.address=10.132.144.24:10020
mapreduce.jobhistory.webapp.address=10.132.144.24:19888

# MapReduceæ¡†æ¶é…ç½®
mapreduce.framework.name=yarn

# ç”¨æˆ·èº«ä»½å’Œç¯å¢ƒé…ç½®
hadoop.user.name=UM
hadoop.environment=development
```

## ç¯å¢ƒè¦æ±‚

- Java 8 æˆ–æ›´é«˜ç‰ˆæœ¬
- Apache Hadoop 3.x
- Apache Maven 3.6+
- YARNé›†ç¾¤ï¼ˆå¯ä»¥æ˜¯å•èŠ‚ç‚¹ä¼ªåˆ†å¸ƒå¼ï¼‰

## å¿«é€Ÿå¼€å§‹

### 1. ç¼–è¯‘é¡¹ç›®

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd yarn-mapreduce-demo

# ç¼–è¯‘å¹¶æ‰“åŒ…
mvn clean package
```

### 2. å‡†å¤‡æµ‹è¯•æ•°æ®

```bash
# åˆ›å»ºHDFSè¾“å…¥ç›®å½•
hdfs dfs -mkdir -p /input/wordcount

# ä¸Šä¼ æµ‹è¯•æ–‡ä»¶
echo "hello world hello hadoop hello yarn" > test.txt
hdfs dfs -put test.txt /input/wordcount/
```

### 3. è¿è¡ŒWordCountç¤ºä¾‹

```bash
# æ–¹å¼1ï¼šä½¿ç”¨hadoopå‘½ä»¤è¿è¡Œ
hadoop jar target/yarn-mapreduce-demo-1.0.0.jar \
  com.bigdata.mapreduce.wordcount.WordCountDriver \
  /input/wordcount /output/wordcount

# æ–¹å¼2ï¼šä½¿ç”¨yarnå‘½ä»¤è¿è¡Œ
yarn jar target/yarn-mapreduce-demo-1.0.0.jar \
  com.bigdata.mapreduce.wordcount.WordCountDriver \
  /input/wordcount /output/wordcount
```

### 4. æŸ¥çœ‹ä½œä¸šç»“æœ

ä½œä¸šå®Œæˆåï¼Œç¨‹åºä¼šè‡ªåŠ¨æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å’Œç»“æœæŸ¥çœ‹æ–¹æ³•ï¼š

#### 4.1 æ§åˆ¶å°è¾“å‡ºç»Ÿè®¡ä¿¡æ¯

```
=== Job Statistics ===
Job ID: job_1234567890123_0001
Map Input Records: 1000
Map Output Records: 5000
Reduce Input Records: 5000
Reduce Output Records: 500
HDFS Bytes Read: 10 MB
HDFS Bytes Written: 2 MB

=== Output Results ===
Results are saved to: /output/wordcount
```

#### 4.2 æŸ¥çœ‹ç»“æœçš„æ–¹æ³•

**æ–¹æ³•1ï¼šHDFS Web UIï¼ˆæ¨èï¼‰**
```
è®¿é—®ï¼šhttp://10.132.144.24:9870/explorer.html#/output/wordcount
```

**æ–¹æ³•2ï¼šå‘½ä»¤è¡ŒæŸ¥çœ‹**
```bash
# æŸ¥çœ‹æ‰€æœ‰ç»“æœæ–‡ä»¶
hdfs dfs -cat /output/wordcount/*

# æŸ¥çœ‹ç›®å½•ç»“æ„
hdfs dfs -ls /output/wordcount
```

**æ–¹æ³•3ï¼šä¸‹è½½åˆ°æœ¬åœ°**
```bash
# ä¸‹è½½ç»“æœåˆ°æœ¬åœ°
hdfs dfs -get /output/wordcount ./local_results
```

#### 4.3 YARN Web UI ç›‘æ§

è®¿é—® YARN Web UI æŸ¥çœ‹ä½œä¸šè¯¦æƒ…ï¼š
```
http://10.132.144.24:8088
```

> ğŸ“– **è¯¦ç»†çš„ç»“æœæŸ¥çœ‹æŒ‡å—**ï¼šè¯·å‚è€ƒ [MapReduce ä½œä¸šç»“æœæŸ¥çœ‹æŒ‡å—](../../docs/tutorials/mapreduce-results-guide.md)

## è¯¦ç»†åŠŸèƒ½è¯´æ˜

### WordCount MapReduceç¨‹åº

#### WordCountMapper
- è´Ÿè´£å°†è¾“å…¥æ–‡æœ¬åˆ†è¯å¹¶è¾“å‡º`<å•è¯, 1>`é”®å€¼å¯¹
- æ”¯æŒå•è¯æ¸…ç†å’Œè¿‡æ»¤
- åŒ…å«è¯¦ç»†çš„æ—¥å¿—è®°å½•

#### WordCountReducer
- æ±‡æ€»ç›¸åŒå•è¯çš„è®¡æ•°
- æ”¯æŒé«˜é¢‘è¯æ±‡è¯†åˆ«
- æä¾›ç»Ÿè®¡ä¿¡æ¯è¾“å‡º

#### WordCountDriver
- MapReduceä½œä¸šçš„ä¸»å…¥å£
- æ”¯æŒYARNé›†ç¾¤é…ç½®
- åŒ…å«ä½œä¸šç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½

### YARNå·¥å…·ç±»

#### YarnResourceMonitor
ç›‘æ§YARNé›†ç¾¤èµ„æºä½¿ç”¨æƒ…å†µï¼š

```java
YarnResourceMonitor monitor = new YarnResourceMonitor();
monitor.init();

// æ‰“å°é›†ç¾¤æŒ‡æ ‡
monitor.printClusterMetrics();

// æ‰“å°èŠ‚ç‚¹æŠ¥å‘Š
monitor.printNodeReports();

// ç›‘æ§åº”ç”¨ç¨‹åº
monitor.printApplications(EnumSet.of(YarnApplicationState.RUNNING));

monitor.close();
```

#### YarnApplicationSubmitter
ç¼–ç¨‹æ–¹å¼æäº¤åº”ç”¨ç¨‹åºåˆ°YARNï¼š

```java
YarnApplicationSubmitter submitter = new YarnApplicationSubmitter();
submitter.init();

// æäº¤MapReduceåº”ç”¨
ApplicationId appId = submitter.submitMapReduceApplication(
    "WordCount", 
    "/apps/wordcount.jar", 
    "com.bigdata.mapreduce.wordcount.WordCountDriver",
    new String[]{"/input", "/output"},
    "default"
);

// ç›‘æ§åº”ç”¨æ‰§è¡Œ
FinalApplicationStatus status = submitter.monitorApplication(appId, 600000);

submitter.close();
```

#### YarnConfigManager
ç®¡ç†å’Œä¼˜åŒ–YARNé…ç½®ï¼š

```java
YarnConfigManager configManager = new YarnConfigManager();

// é…ç½®ResourceManager
configManager.configureResourceManager("localhost", 8032, 8088);

// é…ç½®NodeManagerèµ„æº
configManager.configureNodeManagerResources(8192, 4, 100);

// é…ç½®è°ƒåº¦å™¨
configManager.configureScheduler(
    "org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler");

// åº”ç”¨æ€§èƒ½ä¼˜åŒ–
configManager.applyPerformanceOptimizations();

// éªŒè¯é…ç½®
boolean isValid = configManager.validateConfiguration();
```

## é«˜çº§ç”¨æ³•

### 1. è‡ªå®šä¹‰YARNé…ç½®

åˆ›å»º`yarn-site.xml`é…ç½®æ–‡ä»¶ï¼š

```xml
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>your-rm-host</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>8192</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>4</value>
    </property>
</configuration>
```

### 2. å¤šé˜Ÿåˆ—é…ç½®

é…ç½®å®¹é‡è°ƒåº¦å™¨æ”¯æŒå¤šé˜Ÿåˆ—ï¼š

```java
// åœ¨YarnConfigManagerä¸­é…ç½®å¤šé˜Ÿåˆ—
configManager.configureScheduler(
    "org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler");

// æäº¤åˆ°ç‰¹å®šé˜Ÿåˆ—
ApplicationId appId = submitter.submitMapReduceApplication(
    "WordCount", jarPath, mainClass, args, "production");
```

### 3. æ€§èƒ½è°ƒä¼˜

#### MapReduceæ€§èƒ½ä¼˜åŒ–
```java
// åœ¨WordCountDriverä¸­è®¾ç½®ä¼˜åŒ–å‚æ•°
conf.setInt("mapreduce.map.memory.mb", 2048);
conf.setInt("mapreduce.reduce.memory.mb", 4096);
conf.set("mapreduce.map.java.opts", "-Xmx1536m");
conf.set("mapreduce.reduce.java.opts", "-Xmx3072m");
```

#### YARNèµ„æºä¼˜åŒ–
```java
// åº”ç”¨æ€§èƒ½ä¼˜åŒ–é…ç½®
configManager.applyPerformanceOptimizations();

// è‡ªå®šä¹‰ä¼˜åŒ–
Map<String, String> customOptimizations = new HashMap<>();
customOptimizations.put("yarn.scheduler.capacity.node-locality-delay", "40");
customOptimizations.put("yarn.nodemanager.vmem-check-enabled", "false");
```

## ç›‘æ§å’Œè°ƒè¯•

### 1. åº”ç”¨ç¨‹åºç›‘æ§

```bash
# æŸ¥çœ‹YARNåº”ç”¨åˆ—è¡¨
yarn application -list

# æŸ¥çœ‹åº”ç”¨è¯¦æƒ…
yarn application -status application_xxx

# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
yarn logs -applicationId application_xxx
```

### 2. é›†ç¾¤ç›‘æ§

è®¿é—®YARN Web UIï¼š
- ResourceManager: http://your-rm-host:8088
- NodeManager: http://your-nm-host:8042
- MapReduce History Server: http://your-history-host:19888

### 3. æ€§èƒ½åˆ†æ

ä½¿ç”¨YarnResourceMonitorè·å–è¯¦ç»†çš„èµ„æºä½¿ç”¨æƒ…å†µï¼š

```java
// è·å–é›†ç¾¤èµ„æºåˆ©ç”¨ç‡
ResourceUtilization utilization = monitor.getClusterResourceUtilization();
System.out.println("Memory utilization: " + utilization.getMemoryUtilization() + "%");
System.out.println("CPU utilization: " + utilization.getCoreUtilization() + "%");
```

## æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³é”™è¯¯**
   ```
   Container killed by YARN for exceeding memory limits
   ```
   è§£å†³æ–¹æ¡ˆï¼šå¢åŠ å®¹å™¨å†…å­˜é…ç½®

2. **è¿æ¥ResourceManagerå¤±è´¥**
   ```
   Failed to connect to ResourceManager
   ```
   è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒRMåœ°å€é…ç½®

3. **æƒé™é—®é¢˜**
   ```
   Permission denied
   ```
   è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥HDFSæƒé™å’Œç”¨æˆ·é…ç½®

### æ—¥å¿—åˆ†æ

æŸ¥çœ‹è¯¦ç»†æ—¥å¿—ï¼š
```bash
# ApplicationMasteræ—¥å¿—
yarn logs -applicationId application_xxx -containerId container_xxx

# NodeManageræ—¥å¿—
tail -f $HADOOP_LOG_DIR/yarn-yarn-nodemanager-*.log

# ResourceManageræ—¥å¿—
tail -f $HADOOP_LOG_DIR/yarn-yarn-resourcemanager-*.log
```

## æ‰©å±•å¼€å‘

### 1. è‡ªå®šä¹‰MapReduceç¨‹åº

å‚è€ƒWordCountç¤ºä¾‹ï¼Œåˆ›å»ºè‡ªå·±çš„MapReduceç¨‹åºï¼š

```java
public class CustomMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    // å®ç°è‡ªå®šä¹‰é€»è¾‘
}

public class CustomReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    // å®ç°è‡ªå®šä¹‰é€»è¾‘
}

public class CustomDriver {
    // é…ç½®å’Œæäº¤ä½œä¸š
}
```

### 2. é›†æˆå…¶ä»–å¤§æ•°æ®ç»„ä»¶

- **Spark on YARN**: è¿è¡ŒSparkåº”ç”¨ç¨‹åº
- **Flink on YARN**: è¿è¡ŒFlinkæµå¤„ç†ä½œä¸š
- **HBase**: ä¸HBaseé›†æˆè¿›è¡Œæ•°æ®å¤„ç†

## è´¡çŒ®æŒ‡å—

1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€Pull Request

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨Apache License 2.0è®¸å¯è¯ã€‚è¯¦æƒ…è¯·å‚é˜…[LICENSE](LICENSE)æ–‡ä»¶ã€‚

## è”ç³»æ–¹å¼

- é¡¹ç›®ç»´æŠ¤è€…ï¼šBigData Team
- é‚®ç®±ï¼šbigdata@example.com
- é¡¹ç›®åœ°å€ï¼šhttps://github.com/bigdata-team/yarn-mapreduce-demo

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-01-15)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- å®ç°WordCount MapReduceç¤ºä¾‹
- æ·»åŠ YARNèµ„æºç›‘æ§å·¥å…·
- æ·»åŠ åº”ç”¨ç¨‹åºæäº¤å·¥å…·
- æ·»åŠ é…ç½®ç®¡ç†å·¥å…·
- å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹