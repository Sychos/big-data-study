# HDFS Java API ç¤ºä¾‹é¡¹ç›®

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„HDFS Java APIæ“ä½œç¤ºä¾‹é¡¹ç›®ï¼Œæ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨Javaç¨‹åºä¸Hadoop HDFSè¿›è¡Œäº¤äº’ã€‚

## é¡¹ç›®ç»“æ„

```
hdfs-java-demo/
â”œâ”€â”€ pom.xml                                    # Mavené…ç½®æ–‡ä»¶
â”œâ”€â”€ README.md                                  # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/
â”‚   â”‚   â”‚   â””â”€â”€ com/
â”‚   â”‚   â”‚       â””â”€â”€ bigdata/
â”‚   â”‚   â”‚           â””â”€â”€ hdfs/
â”‚   â”‚   â”‚               â”œâ”€â”€ util/
â”‚   â”‚   â”‚               â”‚   â””â”€â”€ HDFSUtil.java          # HDFSå·¥å…·ç±»
â”‚   â”‚   â”‚               â”œâ”€â”€ example/
â”‚   â”‚   â”‚               â”‚   â”œâ”€â”€ HDFSBasicExample.java  # åŸºç¡€æ“ä½œç¤ºä¾‹
â”‚   â”‚   â”‚               â”‚   â””â”€â”€ HDFSLargeFileExample.java # å¤§æ–‡ä»¶å¤„ç†ç¤ºä¾‹
â”‚   â”‚   â”‚               â””â”€â”€ project/
â”‚   â”‚   â”‚                   â””â”€â”€ LogAnalyzer.java       # æ—¥å¿—åˆ†æé¡¹ç›®æ¡ˆä¾‹
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â””â”€â”€ log4j.properties              # æ—¥å¿—é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ java/
â”‚           â””â”€â”€ com/
â”‚               â””â”€â”€ bigdata/
â”‚                   â””â”€â”€ hdfs/
â”‚                       â””â”€â”€ util/
â”‚                           â””â”€â”€ HDFSUtilTest.java      # å•å…ƒæµ‹è¯•
```

## åŠŸèƒ½ç‰¹æ€§

### 1. HDFSUtilå·¥å…·ç±»
- âœ… åˆ›å»ºç›®å½•
- âœ… ä¸Šä¼ æ–‡ä»¶åˆ°HDFS
- âœ… ä»HDFSä¸‹è½½æ–‡ä»¶
- âœ… åˆ é™¤HDFSæ–‡ä»¶æˆ–ç›®å½•
- âœ… åˆ—å‡ºç›®å½•å†…å®¹
- âœ… è¯»å–HDFSæ–‡ä»¶å†…å®¹
- âœ… å†™å…¥å†…å®¹åˆ°HDFSæ–‡ä»¶
- âœ… è·å–æ–‡ä»¶çŠ¶æ€ä¿¡æ¯
- âœ… è¿æ¥ç®¡ç†å’Œèµ„æºé‡Šæ”¾

### 2. ç¤ºä¾‹ç¨‹åº
- **åŸºç¡€æ“ä½œç¤ºä¾‹**: æ¼”ç¤ºHDFSçš„åŸºæœ¬æ–‡ä»¶æ“ä½œ
- **å¤§æ–‡ä»¶å¤„ç†ç¤ºä¾‹**: æ¼”ç¤ºå¦‚ä½•é«˜æ•ˆå¤„ç†å¤§æ–‡ä»¶
- **æ—¥å¿—åˆ†æé¡¹ç›®**: å®Œæ•´çš„Webæ—¥å¿—åˆ†ææ¡ˆä¾‹

### 3. å•å…ƒæµ‹è¯•
- å®Œæ•´çš„å•å…ƒæµ‹è¯•è¦†ç›–
- è‡ªåŠ¨åŒ–æµ‹è¯•ç¯å¢ƒæ­å»ºå’Œæ¸…ç†
- å„ç§è¾¹ç•Œæƒ…å†µæµ‹è¯•

## ç¯å¢ƒè¦æ±‚

- **JDK**: 1.8+
- **Maven**: 3.5+
- **Hadoop**: 3.3.4ï¼ˆå·²å®‰è£…å¹¶å¯åŠ¨ï¼‰
- **æ“ä½œç³»ç»Ÿ**: Windows 10/Linux/macOS

## å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†é¡¹ç›®
```bash
cd e:\devCode\big-data-study\code
cd hdfs-java-demo
```

### 2. ç¡®ä¿Hadoopç¯å¢ƒè¿è¡Œ
```bash
# å¯åŠ¨HadoopæœåŠ¡
start-dfs.cmd
start-yarn.cmd

# éªŒè¯HDFSæœåŠ¡
hdfs dfsadmin -report
```

### 3. ç¼–è¯‘é¡¹ç›®
```bash
mvn clean compile
```

### 4. è¿è¡Œç¤ºä¾‹

#### åŸºç¡€æ“ä½œç¤ºä¾‹
```bash
mvn exec:java -Dexec.mainClass="com.bigdata.hdfs.example.HDFSBasicExample"
```

#### å¤§æ–‡ä»¶å¤„ç†ç¤ºä¾‹
```bash
mvn exec:java -Dexec.mainClass="com.bigdata.hdfs.example.HDFSLargeFileExample"
```

#### æ—¥å¿—åˆ†æé¡¹ç›®
```bash
mvn exec:java -Dexec.mainClass="com.bigdata.hdfs.project.LogAnalyzer"
```

### 5. è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
mvn test

# è¿è¡Œç‰¹å®šæµ‹è¯•ç±»
mvn test -Dtest=HDFSUtilTest
```

## é…ç½®è¯´æ˜

### HDFSè¿æ¥é…ç½®
åœ¨ä»£ç ä¸­ä¿®æ”¹HDFSè¿æ¥åœ°å€ï¼š
```java
// é»˜è®¤é…ç½®
HDFSUtil hdfsUtil = new HDFSUtil("hdfs://10.132.144.24:9000");

// å¦‚æœä½ çš„HDFSè¿è¡Œåœ¨ä¸åŒç«¯å£ï¼Œè¯·ä¿®æ”¹ç›¸åº”åœ°å€
// HDFSUtil hdfsUtil = new HDFSUtil("hdfs://your-hadoop-host:9000");
```

### ç”¨æˆ·æƒé™é…ç½®
é¡¹ç›®é»˜è®¤ä½¿ç”¨"hadoop"ç”¨æˆ·èº«ä»½è®¿é—®HDFSï¼Œå¦‚éœ€ä¿®æ”¹ï¼š
```java
// åœ¨HDFSUtilæ„é€ å‡½æ•°ä¸­ä¿®æ”¹
System.setProperty("HADOOP_USER_NAME", "your-username");
```

### æ—¥å¿—çº§åˆ«é…ç½®
ä¿®æ”¹ `src/main/resources/log4j.properties` æ–‡ä»¶ï¼š
```properties
# ä¿®æ”¹æ—¥å¿—çº§åˆ«
log4j.rootLogger=DEBUG, stdout  # æ”¹ä¸ºDEBUGå¯çœ‹åˆ°æ›´è¯¦ç»†æ—¥å¿—
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬æ–‡ä»¶æ“ä½œ
```java
public class QuickStart {
    public static void main(String[] args) throws Exception {
        // 1. åˆå§‹åŒ–HDFSè¿æ¥
        HDFSUtil hdfsUtil = new HDFSUtil("hdfs://10.132.144.24:9000");
        
        // 2. åˆ›å»ºç›®å½•
        hdfsUtil.createDirectory("/user/myapp");
        
        // 3. å†™å…¥æ–‡ä»¶
        hdfsUtil.writeFile("/user/myapp/hello.txt", "Hello HDFS!");
        
        // 4. è¯»å–æ–‡ä»¶
        String content = hdfsUtil.readFile("/user/myapp/hello.txt");
        System.out.println("æ–‡ä»¶å†…å®¹: " + content);
        
        // 5. åˆ—å‡ºç›®å½•
        hdfsUtil.listFiles("/user/myapp");
        
        // 6. å…³é—­è¿æ¥
        hdfsUtil.close();
    }
}
```

### æ–‡ä»¶ä¸Šä¼ ä¸‹è½½
```java
// ä¸Šä¼ æœ¬åœ°æ–‡ä»¶åˆ°HDFS
hdfsUtil.uploadFile("local_file.txt", "/user/myapp/remote_file.txt");

// ä»HDFSä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°
hdfsUtil.downloadFile("/user/myapp/remote_file.txt", "downloaded_file.txt");
```

### å¤§æ–‡ä»¶å¤„ç†
```java
// æµå¼è¯»å–å¤§æ–‡ä»¶
FSDataInputStream in = fs.open(new Path("/user/data/large_file.txt"));
BufferedReader reader = new BufferedReader(new InputStreamReader(in, "UTF-8"));

String line;
while ((line = reader.readLine()) != null) {
    // å¤„ç†æ¯ä¸€è¡Œæ•°æ®
    processLine(line);
}

reader.close();
in.close();
```

## å¸¸è§é—®é¢˜è§£å†³

### 1. è¿æ¥è¶…æ—¶
```java
// åœ¨Configurationä¸­è®¾ç½®è¶…æ—¶å‚æ•°
Configuration conf = new Configuration();
conf.set("ipc.client.connect.timeout", "10000");
conf.set("ipc.client.connect.max.retries", "3");
```

### 2. æƒé™é—®é¢˜
```bash
# è®¾ç½®HDFSç›®å½•æƒé™
hdfs dfs -chmod 777 /user
hdfs dfs -chown hadoop:hadoop /user
```

### 3. å†…å­˜ä¸è¶³
```bash
# è®¾ç½®JVMå‚æ•°
export MAVEN_OPTS="-Xmx2g -Xms1g"
```

### 4. ç¼–ç é—®é¢˜
ç¡®ä¿æ‰€æœ‰æ–‡ä»¶æ“ä½œéƒ½ä½¿ç”¨UTF-8ç¼–ç ï¼š
```java
// è¯»å–æ—¶æŒ‡å®šç¼–ç 
String content = new String(bytes, "UTF-8");

// å†™å…¥æ—¶æŒ‡å®šç¼–ç 
outputStream.write(content.getBytes("UTF-8"));
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹é‡æ“ä½œ
```java
// æ‰¹é‡ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
for (String localFile : localFiles) {
    hdfsUtil.uploadFile(localFile, "/user/data/" + new File(localFile).getName());
}
```

### 2. ç¼“å†²åŒºä¼˜åŒ–
```java
// è®¾ç½®åˆé€‚çš„ç¼“å†²åŒºå¤§å°
Configuration conf = new Configuration();
conf.set("io.file.buffer.size", "131072"); // 128KB
```

### 3. è¿æ¥å¤ç”¨
```java
// å¤ç”¨HDFSUtilå®ä¾‹ï¼Œé¿å…é¢‘ç¹åˆ›å»ºè¿æ¥
HDFSUtil hdfsUtil = new HDFSUtil("hdfs://10.132.144.24:9000");
try {
    // æ‰§è¡Œå¤šä¸ªæ“ä½œ
    hdfsUtil.createDirectory("/user/data1");
    hdfsUtil.createDirectory("/user/data2");
    // ...
} finally {
    hdfsUtil.close();
}
```

## æ‰©å±•å¼€å‘

### 1. æ·»åŠ æ–°åŠŸèƒ½
åœ¨ `HDFSUtil` ç±»ä¸­æ·»åŠ æ–°çš„æ–¹æ³•ï¼š
```java
/**
 * å¤åˆ¶HDFSæ–‡ä»¶
 */
public boolean copyFile(String srcPath, String destPath) {
    // å®ç°æ–‡ä»¶å¤åˆ¶é€»è¾‘
}
```

### 2. è‡ªå®šä¹‰é…ç½®
åˆ›å»ºé…ç½®æ–‡ä»¶ `hdfs-config.properties`ï¼š
```properties
hdfs.uri=hdfs://10.132.144.24:9000
hdfs.user=hadoop
hdfs.buffer.size=131072
```

### 3. æ·»åŠ ç›‘æ§
```java
// æ·»åŠ æ“ä½œè€—æ—¶ç›‘æ§
long startTime = System.currentTimeMillis();
// æ‰§è¡ŒHDFSæ“ä½œ
long endTime = System.currentTimeMillis();
logger.info("æ“ä½œè€—æ—¶: {} æ¯«ç§’", endTime - startTime);
```

## å­¦ä¹ è·¯å¾„

1. **åŸºç¡€å­¦ä¹ **: å…ˆè¿è¡Œ `HDFSBasicExample`ï¼Œç†è§£åŸºæœ¬æ“ä½œ
2. **è¿›é˜¶å­¦ä¹ **: è¿è¡Œ `HDFSLargeFileExample`ï¼Œå­¦ä¹ å¤§æ–‡ä»¶å¤„ç†
3. **é¡¹ç›®å®è·µ**: è¿è¡Œ `LogAnalyzer`ï¼Œäº†è§£å®é™…åº”ç”¨åœºæ™¯
4. **æ·±å…¥ç ”ç©¶**: é˜…è¯»æºç ï¼Œç†è§£HDFS APIåŸç†
5. **æ‰©å±•å¼€å‘**: åŸºäºé¡¹ç›®æ¡†æ¶å¼€å‘è‡ªå·±çš„åº”ç”¨

## ç›¸å…³èµ„æº

- [Hadoopå®˜æ–¹æ–‡æ¡£](https://hadoop.apache.org/docs/r3.3.4/)
- [HDFSæ¶æ„æŒ‡å—](https://hadoop.apache.org/docs/r3.3.4/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [Hadoop Java APIæ–‡æ¡£](https://hadoop.apache.org/docs/r3.3.4/api/)

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ï¼Œè¯¦è§LICENSEæ–‡ä»¶ã€‚

---

**Happy Coding! ğŸš€**